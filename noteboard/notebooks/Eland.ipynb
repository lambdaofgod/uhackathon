{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9a0532-be4c-489d-b319-9a33afec4c0b",
   "metadata": {},
   "source": [
    "# Storing notes in Elasticsearch using Eland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5698630-617a-4c1f-aebf-4af81870f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import glob \n",
    "import logging\n",
    "import eland as ed\n",
    "import elasticsearch\n",
    "import matplotlib.pyplot as plt\n",
    "from noteboard import Org\n",
    "\n",
    "import warnings\n",
    "from elasticsearch.exceptions import ElasticsearchWarning\n",
    "warnings.simplefilter('ignore', ElasticsearchWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6da109-4204-4aa9-a074-74b544c433ad",
   "metadata": {},
   "source": [
    "## Org node elements\n",
    "\n",
    "OrgElement represents an org-mode subheading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a670946-e639-48f1-b3f9-e0de89bc71ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/python_backend.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/m_word.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/lisp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/rust.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/big_thunk.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/pages/contents.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/projects/llmtutor.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/langchain.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/auto_custodian.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/research_guide.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/machine_learning.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/rwkv.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/pytorch_onnx.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/hyperbolic.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/ml_diary.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/nn.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/information_retrieval.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/general.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/research.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/gpt_token_count.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/hypernotes.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/krypto.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/bert.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/dl_notes.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/inbox.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/graphs.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/mlops_chatgpt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/image_gen.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/polish_numbers.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/multilingual_pos.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/llms.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/medsi.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230304141858-llm.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132631-org_stuff.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230226201852-tasks.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230215104221-drug_availability.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132742-org_test.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132545-org_stuff.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230707213623-python.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230712133059-elixir_zen_of_python.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132341-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230316221156-rasa.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132420-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132346-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/ekonomia.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/stonks.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/crypto.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/finanse.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/general_dev/programming_misc.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_abstrakt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka4.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_proposed_approach.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_tmp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_roam.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/chatgpt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/inbox.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_mid.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/latex_guix.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_results.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_data.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_openai.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_new.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/medsi.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/praca.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/lekointerakcjomat.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/medsi_research.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/soft_skills.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/botpress.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/rejestracja.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/wywiad_medyczny.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/sd2.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/studia.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/muzyka.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/scratch.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/art.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/creative.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/llm_docs/querying.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/knowledge/qa_langchain_qdrant.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/tasks/tasks.org elements\n",
      "WARNING:root:'ID'\n"
     ]
    }
   ],
   "source": [
    "roam_nodes_df = Org.to_df(Org.load_dir_generator(\"/home/kuba/Projects/org\", only_root_contents=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04eba59a-d307-40f7-b820-cea30d121872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/python_backend.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/m_word.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/lisp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/rust.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/langs/big_thunk.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/pages/contents.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/projects/llmtutor.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/langchain.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/auto_custodian.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/research_guide.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/machine_learning.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/rwkv.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/pytorch_onnx.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/hyperbolic.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/ml_diary.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/nn.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/information_retrieval.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/general.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/research.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/gpt_token_count.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/hypernotes.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/krypto.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/bert.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/dl_notes.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/inbox.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/graphs.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/mlops_chatgpt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/image_gen.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/polish_numbers.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/multilingual_pos.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/ml/llms.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/medsi.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230304141858-llm.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132631-org_stuff.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230226201852-tasks.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230215104221-drug_availability.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132742-org_test.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132545-org_stuff.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230707213623-python.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230712133059-elixir_zen_of_python.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132341-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230316221156-rasa.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132420-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/roam/20230611132346-detangle_exp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/ekonomia.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/stonks.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/crypto.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/econ/finanse.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/general_dev/programming_misc.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_abstrakt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka4.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_proposed_approach.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_tmp.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_roam.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/chatgpt.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/inbox.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_mid.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/latex_guix.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_results.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/magisterka_data.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_openai.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/mgr/mgr_new.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/medsi.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/praca.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/lekointerakcjomat.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/medsi_research.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/soft_skills.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/botpress.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/rejestracja.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/work/wywiad_medyczny.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/sd2.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/studia.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/muzyka.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/scratch.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/art.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/other/creative.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/llm_docs/querying.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/knowledge/qa_langchain_qdrant.org elements\n",
      "WARNING:root:'ID'\n",
      "WARNING:root:cannot parse /home/kuba/Projects/org/tasks/tasks.org elements\n",
      "WARNING:root:'ID'\n"
     ]
    }
   ],
   "source": [
    "roam_df = Org.to_df(Org.load_dir_generator(\"/home/kuba/Projects/org\", only_root_contents=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ef7c5d-e428-4ee1-9443-55cbe74d7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = elasticsearch.Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme':'http'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2227a540-be1a-49c9-ad30-7b690210f8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.cache/pypoetry/virtualenvs/noteboard-pn0B81or-py3.10/lib/python3.10/site-packages/eland/field_mappings.py:951: UserWarning: Eland major version (8.11.1) doesn't match the major version of the Elasticsearch server (7.17.16) which can lead to compatibility issues. Your Eland major version should be the same as your cluster major version.\n",
      "  elastic_version = es_version(client)\n"
     ]
    }
   ],
   "source": [
    "existing_behavior = \"replace\"\n",
    "\n",
    "roam_nodes_elastic_df = ed.pandas_to_eland(\n",
    "    roam_nodes_df,\n",
    "    es_client=es_client,\n",
    "    es_dest_index=\"org_roam_nodes\",\n",
    "    es_type_overrides={\"text\": \"text\"},\n",
    "    es_if_exists=existing_behavior\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d9f98-d6d8-4233-8b38-05b67ebc2e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014e1703-603c-4a32-a773-32309f4bb6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roam_df[\"text\"].apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16789d18-89b2-4ff7-8b0a-9d3fc2da1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5420 entries, 0 to 5419\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   org_id     5420 non-null   object\n",
      " 1   file_name  5420 non-null   object\n",
      " 2   heading    5420 non-null   object\n",
      " 3   level      5420 non-null   int64 \n",
      " 4   body       5420 non-null   object\n",
      " 5   links      5420 non-null   object\n",
      " 6   text       5420 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 296.5+ KB\n"
     ]
    }
   ],
   "source": [
    "roam_nodes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f34ec4-0afc-4873-8520-21f9f5d4cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   org_id     918 non-null    object\n",
      " 1   file_name  918 non-null    object\n",
      " 2   heading    918 non-null    object\n",
      " 3   level      918 non-null    int64 \n",
      " 4   body       918 non-null    object\n",
      " 5   links      918 non-null    object\n",
      " 6   text       918 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 50.3+ KB\n"
     ]
    }
   ],
   "source": [
    "roam_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c627579-e45c-455b-909a-53fa23d39348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "existing_behavior = \"replace\"\n",
    "\n",
    "try:\n",
    "        \n",
    "    roam_elastic_df = ed.pandas_to_eland(\n",
    "        roam_df,\n",
    "        es_client=es_client,\n",
    "        es_dest_index=\"org_roam\",\n",
    "        es_type_overrides={\"text\": {\"type\": \"text\"}},\n",
    "        es_if_exists=existing_behavior\n",
    "    )\n",
    "    print(\"success\")\n",
    "except Exception as e:\n",
    "    print(\"failure\")\n",
    "    exc = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "36fe17f1-cb89-47e6-96f2-90286da1f9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<p>151 rows × 0 columns</p>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [8, 21, 33, 45, 47, 49, 898, 899, 912, 914, 916]\n",
       "\n",
       "[151 rows x 0 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roam_elastic_df.es_match(\"llms\", columns=[\"text\"], fuzziness=1).filter([\"_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "75683fef-f836-47da-9eb7-20a648e31da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_query =         {\n",
    "    \"fuzzy\": {\n",
    "            \"text\": {\n",
    "                \"value\": \"llms\",\n",
    "                \"fuzziness\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "llm_query_results_df = roam_elastic_df.es_query(llm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04632f6b-813e-4d5e-90b5-c964c17a1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es_index_pattern: org_roam\n",
      "Index:\n",
      " es_index_field: _id\n",
      " is_source_field: False\n",
      "Mappings:\n",
      " capabilities:\n",
      "          es_field_name  is_source es_dtype es_date_format pd_dtype  is_searchable  is_aggregatable  is_scripted aggregatable_es_field_name\n",
      "body               body       True  keyword           None   object           True             True        False                       body\n",
      "file_name     file_name       True  keyword           None   object           True             True        False                  file_name\n",
      "heading         heading       True  keyword           None   object           True             True        False                    heading\n",
      "level             level       True     long           None    int64           True             True        False                      level\n",
      "links             links       True  keyword           None   object           True             True        False                      links\n",
      "org_id           org_id       True  keyword           None   object           True             True        False                     org_id\n",
      "text               text       True     text           None   object           True            False        False                       None\n",
      "Operations:\n",
      " tasks: [('boolean_filter': ('boolean_filter': {'fuzzy': {'text': {'value': 'llms', 'fuzziness': 1}}}))]\n",
      " size: None\n",
      " sort_params: None\n",
      " _source: ['body', 'file_name', 'heading', 'level', 'links', 'org_id', 'text']\n",
      " body: {'query': {'fuzzy': {'text': {'value': 'llms', 'fuzziness': 1}}}}\n",
      " post_processing: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_query_results_df.es_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73401ff7-facf-4a30-8229-6d36bf06f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for err in exc.errors:\n",
    "#    print(err[\"index\"][\"data\"][\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db6f0ca6-79e6-4bc2-ba0f-6e1f7a09739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'org_roam': {'mappings': {'properties': {'body': {'type': 'keyword'}, 'file_name': {'type': 'keyword'}, 'heading': {'type': 'keyword'}, 'level': {'type': 'long'}, 'links': {'type': 'keyword'}, 'org_id': {'type': 'keyword'}, 'text': {'type': 'text'}}}}})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.indices.get_mapping(index=\"org_roam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8bb96b27-c37b-4282-994c-b196ed5c7797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '381',\n",
       "  '_score': 7.240573,\n",
       "  '_source': {'org_id': 'dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b',\n",
       "   'file_name': '20230227210357-llms',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms\\n\\n\\n',\n",
       "   'links': ['97379691-82f0-4fcd-a521-2ab3aeacda8a',\n",
       "    '8b7560f7-9233-41c2-9939-a51497232943',\n",
       "    '35740f44-515a-4bf6-bfd1-cd949e827913',\n",
       "    '4d2e3520-1973-4c93-bdb1-80db1a47f065',\n",
       "    '3d574d6f-f79d-437c-8c95-e361515efe3b',\n",
       "    '8689333b-0885-4848-9bfe-db464db3fcb2',\n",
       "    '4f718ddb-fa01-40ca-b76b-ec265f3c8d21',\n",
       "    '62249719-cbc3-44bd-a6b6-55be09fed98f',\n",
       "    '1e699344-4440-4347-ac1e-089a04ef0504',\n",
       "    'fad664b1-7ae9-4c7e-b2b0-87298b88d8e4',\n",
       "    'c8155236-245e-4025-9db6-74e761012342',\n",
       "    'ab5ccbbf-5893-4d42-8785-6c8e51d0e9e2'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b\\n:END:\\n#+title: llms\\n\\n\\n\\n\\n* Logit bias\\n\\nUsed to constrain generation\\n\\n\\n\\n* Vocabulary\\n\\n\\n** Grounding\\n\\nBasing LLM outputs on some sort of knowledge\\n\\n\\n* Topics\\n\\n[[id:97379691-82f0-4fcd-a521-2ab3aeacda8a][llms/constrained_generation]]\\n\\n[[id:8b7560f7-9233-41c2-9939-a51497232943][llms/finetuning]]\\n\\n[[id:35740f44-515a-4bf6-bfd1-cd949e827913][llms/retrieval_augmented]]\\n\\n[[id:4d2e3520-1973-4c93-bdb1-80db1a47f065][lm_qa]]\\n\\n[[id:3d574d6f-f79d-437c-8c95-e361515efe3b][llms/utils]]\\n\\n[[id:8689333b-0885-4848-9bfe-db464db3fcb2][llms/lora]]\\n\\n[[id:4f718ddb-fa01-40ca-b76b-ec265f3c8d21][llms/models]]\\n\\n[[id:62249719-cbc3-44bd-a6b6-55be09fed98f][llms/general_ai]]\\n\\n\\n* Tools\\n\\n\\n** Langchain\\n[[id:1e699344-4440-4347-ac1e-089a04ef0504][llms/langchain]]\\n\\n\\n\\n** LLaMaIndex\\n\\ndoesn\\'t even have anything other than OpenAI/langchain for embeddings XDDDDDD\\n\\n\\n* TL;DR\\n\\nLLMs (large language models) are models that are trained to predict next word given previous ones.\\n\\nCurrently most of LLMs use transformer architecture.\\n\\nIn actuality they predict tokens which are smaller units than words. LLM services like ChatGPT bill by number of tokens, see tokenization for details.\\n\\n\\n* Capabilities\\n\\nIt was observed around 2022 that if you feed enough data to a big model different ML tasks can be posed as text generation.\\n\\nFor example LMs can be fed examples like this for sentiment analysis\\n\\nclassification\\ntext:\\nspieprzaj dziadu\\nsentiment:\\nnegative\\n\\nor liket this for summarization\\n\\ntl;dr\\ntext:\\n<first chapter of The hobbit>\\nsummary:\\nSome white guy smoking pipe tells a bunch of midgets to go on an adventure\\n\\n\\n* Comments\\n\\n\\n** Tokenization\\nTokens are the vocabulary of LMs.\\n\\nTokenization algorithms like Byte-Pair Encoding are given a corpus and they come up with subwords.\\n\\nWhy tokenization:\\n- if words were used as tokens there would be too many of them or some of them would be missign from vocabulary\\n- splitting longer words means that a complex word is represented as a sequence of simpler ones )\\n  example: GPT tokenizer splits \"whataboutism\" into 4 tokens\\n  (this is especially true for languages with more complex morphology like Slavic ones)\\n\\n\\n\\n* Conversational models\\n\\n[[id:fad664b1-7ae9-4c7e-b2b0-87298b88d8e4][conversational_llms]]\\n\\n\\n\\n\\n* List of interesting LLMs <2023-02-27 pon>\\n[[id:c8155236-245e-4025-9db6-74e761012342][llms/interesting]]\\n\\n\\n* Benchmarks\\n\\n[[id:ab5ccbbf-5893-4d42-8785-6c8e51d0e9e2][llms/evaluation]]'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '370',\n",
       "  '_score': 5.9861,\n",
       "  '_source': {'org_id': 'ce612ace-69d4-4519-ba6f-a54fd6769c0a',\n",
       "   'file_name': '20230508154000-llms_logic',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms/logic\\n\\nllms\\n\\nLLM (Large Language Model) such as ChatGPT prompts related to Prolog',\n",
       "   'links': [],\n",
       "   'text': ':PROPERTIES:\\n:ID:       ce612ace-69d4-4519-ba6f-a54fd6769c0a\\n:END:\\n#+title: llms/logic\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\n[[https://swi-prolog.discourse.group/t/llm-large-language-model-such-as-chatgpt-prompts-related-to-prolog/6248][LLM (Large Language Model) such as ChatGPT prompts related to Prolog]]'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '121',\n",
       "  '_score': 5.970832,\n",
       "  '_source': {'org_id': 'd34990bb-15a0-4032-a51b-288ed2459521',\n",
       "   'file_name': '20231226123927-llms_challenges',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms/challenges\\n\\nllms\\n',\n",
       "   'links': ['0182bd3d-adab-4da8-a7b8-42bd77e619ca'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       d34990bb-15a0-4032-a51b-288ed2459521\\n:END:\\n#+title: llms/challenges\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\n\\n* Sources on LLMs\\n\\n[[cite:&kaddour23_chall_applic_large_languag_model]]\\n\\n\\n* Pragmatics and LLM failure modes\\n\\n\\n** [[id:0182bd3d-adab-4da8-a7b8-42bd77e619ca][llms/cooperative_principle]]\\n\\nDo LLMs actually follow CP?\\n\\n\\n** Hallucination\\n\\nHalucinations mean breaking the quality maxim.\\n\\n\\n\\n** Prompt injection\\n\\nMalicious prompts override the default behavior that follows the CP.'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '61',\n",
       "  '_score': 5.9527397,\n",
       "  '_source': {'org_id': 'd32df7ba-044b-48de-af07-e3bff49478c1',\n",
       "   'file_name': '20230510115859-llms_mini',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms/mini\\n\\nllms\\n\\nMaking smaller/more efficient models\\n',\n",
       "   'links': ['6ea33342-b461-4e5a-b8af-f645fa56a10b'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       d32df7ba-044b-48de-af07-e3bff49478c1\\n:END:\\n#+title: llms/mini\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\nMaking smaller/more efficient models\\n\\n\\n* General\\n\\n\\n\\n** Frugal GPT\\n:PROPERTIES:\\n:ID:       c505c9b8-e486-4bb1-ae7a-4a16cba75ba2\\n:END:\\n[[cite:&chen23_frugal]]\\n\\n1) prompt adaptation\\n2) LLM approximation\\n3) LLM cascade\\n\\n\\n\\n* Distillation\\n\\n\\n** Distilling step by step!\\n:PROPERTIES:\\n:ID:       1e8ba26a-fcc6-40e5-893f-464393f62bc4\\n:END:\\n\\n[[cite:&distil_step_by_step]]\\n\\n\\n* Quantization\\n\\n[[id:6ea33342-b461-4e5a-b8af-f645fa56a10b][llm/quantization]]'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '869',\n",
       "  '_score': 5.9414372,\n",
       "  '_source': {'org_id': 'c47db623-8939-4734-946e-e55be3ea2acd',\n",
       "   'file_name': '20230422190758-inbox',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: inbox\\n\\n#+RESULTS:\\n: my-append-to-org-roam-node\\n\\n\\n#+TODO: TODO IN-PROGRESS DONE\\n#+STARTUP: fold\\n',\n",
       "   'links': ['9d2478d7-92a9-4e7a-ad04-66d85bdd52a0',\n",
       "    '90798583-a026-408e-924a-8fa57fe5e3ff',\n",
       "    'cb28a7c7-5cbe-48f9-82c8-bed535f3a94d',\n",
       "    'a10eb046-98f3-409e-8ea1-0218e3bd1a4f',\n",
       "    'ba39ee5b-9e62-4637-8cf2-98cb8a950a8a',\n",
       "    '760b983b-e4df-47e2-8832-0a7270c0183b',\n",
       "    'a862af1c-b442-4da6-9b47-09adc42cbba6',\n",
       "    '35740f44-515a-4bf6-bfd1-cd949e827913',\n",
       "    '64146b02-3dc3-4e33-a570-716191d92f91',\n",
       "    'fad664b1-7ae9-4c7e-b2b0-87298b88d8e4',\n",
       "    'a611adc5-215d-44a8-aadd-b98c46a3a1ec',\n",
       "    '1cafd8f7-cd85-456a-a2e5-a1011edc00e6',\n",
       "    '36515f95-100f-4dbb-bf90-cc88ee76282e',\n",
       "    'f98ad094-a9ea-4a11-ac74-f0441bf26273',\n",
       "    'd4c9cf4c-d352-4e5e-9ed1-669cacff5902',\n",
       "    '0d15b026-1607-4315-90e4-2892d32475a8',\n",
       "    '583ab1be-f878-46fa-b8ba-b8eefbd76ddb',\n",
       "    '34da7672-3542-42ba-b945-a3caa178fb26',\n",
       "    '5412a751-47eb-4843-a431-d08e1cff3f2d',\n",
       "    '8cfb68cf-bd41-414a-9a63-e2408240d25c',\n",
       "    'ee639bd3-1841-4fd1-a84a-1047db49d6dd',\n",
       "    '54f7d50e-5d8b-41c6-9e1a-91624c7a972f',\n",
       "    '81628938-1275-44e4-888f-427f047e4df4',\n",
       "    '165279b9-aaaf-4265-a075-4080f1192ee5',\n",
       "    'e3f417b8-e66a-4db7-a08f-788950d52b17',\n",
       "    'd6b24e1d-ee70-4d57-b5bc-78149feb4802',\n",
       "    '8be4fc30-bac3-4558-b6de-27e7fab1cbd9',\n",
       "    '4b2195e5-4602-4966-971f-0320a373ac30'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       c47db623-8939-4734-946e-e55be3ea2acd\\n:END:\\n#+title: inbox\\n\\n#+RESULTS:\\n: my-append-to-org-roam-node\\n\\n\\n#+TODO: TODO IN-PROGRESS DONE\\n#+STARTUP: fold\\n\\n\\n* Oryginalne OOP\\n- aktorzy\\n- obiekty wymieniają się wiadomociami\\n- WIADOMOŚCI SĄ WARTOŚCIAMI A NIE REFERENCJAMI\\n\\n\\n* LLMy\\n\\n\\n** LLMy i edukacja <2023-03-14 wto>\\n\\nArtykuł Chomskiego o plagiatach\\n\\nMoim zdaniem ChatGPT po prostu pokazuje ułomności obecnego systemu edukacji\\n\\nJeśli nauczyciele dają zadania które łatwo splagiatować to trzeba będzie przejść na jakiś inny sposób oceny\\n\\n*w ogóle jeśli ktoś mówi o tym że ChatGPT jest tylko zdolne do plagiatu to to jest missing the point* - podobnie można powiedzieć że encyklopedie, wikipedia i wyszukiwarki są tylko plagiatorami\\n\\nWartość dodana tkwi w tym że są one nowym interfejsem\\n\\nhttps://simonwillison.net/2023/Mar/11/llama/\\n\\n\\n\\n\\n\\n** Na ile LLMy są świadome możliwości wielu odpowiedzi?\\n\\n** Sprawdzanie czy wyniki są poprawne\\n- klasyfikator\\n- sprawdzanie przez wyszukiwanie\\n- sprawdzanie przez dopytanie - wg schematu albo w stylu Elizy\\n\\nCZY DA SIE TO ODWRÓCIĆ W EDUKACJI?\\n\\n** Generowanie danych v2\\n\\n\\n*** InPars\\n- requires rerankers\\n\\n\\n*** InPars lite\\n\\n- generate with GPT-J 6B and BLOOM 7B\\n\\n- filter queries\\n\\n- rerank with small model like MiniLM\\n\\nWTF small models are cross encoders\\n\\n\\n**** pipeline\\n\\n\\n*** Promptagator\\n- no github\\n- few shot in the sense of /intents/\\n  same queries/documents generate different datasets with respect\\n  to different intents like argument/counter argument\\n\\n\\n[[id:9d2478d7-92a9-4e7a-ad04-66d85bdd52a0][llm/knowledge_index]]\\n\\n\\n\\n** Niepewność\\n\\nW kontekście QA użytkownik może zaakceptować że nie dostanie odpowiedzi od razu.\\n\\nPrzy założeniu 3 zapytań może mieć sens zadawanie hierarchicznie pytań\\n\\nW sensie pytanie 1 jest ogólne, potem dzielimy przestrzeń wyszukiwania itd\\n\\n\\n** Hierarchiczne indeksy\\n\\n\\n** Chomsky itd\\nhttps://lingbuzz.net/lingbuzz/007180\\n\\n\\n* Random\\nhttps://twitter.com/lemire/status/1635736328900935693\\n\\n\\n* Research\\nData portraits\\n\\nData2vec\\n\\n* NLP\\n\\n\\n** Sentence transformers\\n\\nTwo types: cross encoders, bi-encoders.\\n\\nBi-encoders are more relevant in practice as you can encode documents and use vector database.\\n\\n\\n* Toolz\\nLangchain\\nhttps://artifact-research.com/artificial-intelligence/build-your-own-ai-how-to-teach-gpt-to-search-the-web-and-execute-code/\\n\\n\\n* ML\\n\\n\\n** Toole do konfigów\\n\\n\\n*** Hydra\\n\\nComposing configs - config groups\\n\\nSeems like each group is single yaml file\\n\\nWhen running stuff you specify which config group is selected\\n\\nThus it looks like good candidate for grid search\\n\\nBUT I don\\'t see anything that relates config parts\\n\\nLike some config is multistage that depends on previous values\\n\\n\\n* MLOps\\n- jak budować MLOwe zależności?\\n\\n\\n* Programowanie\\n\\n\\n** do czego są\\xa0przydatne smart notatki\\n- zbieranie informacji o podobnym kodzie/funkcjach/klasach\\n- zbieranie informacji o\\n\\n\\n** TODO ogarnij autouzupełnienie w babelu\\n\\n\\n** Mongo\\n\\nPakujesz na pałę dane, nie ma schematu\\n\\nKtoś kto korzysta z tego potem martwi się o parsowanie do odpowiedniego formatu\\n\\n\\n* Inne\\n\\n\\n\\n* Lean\\n\\n[[id:90798583-a026-408e-924a-8fa57fe5e3ff][lean_suggestions]]\\n\\n\\n* Projects\\n\\n\\n** LLMTutor\\n\\n- mamy content z paterona/notatki/transkrypty video\\n- są ludzie którzy na patreonie robią tutoring\\n- LLMy na bazie wiedzy są lepsze niż z całego internetu\\n- własciciel treści jest w stanie ocenić czy generowanie jest OK\\n\\n\\n\\n*** pre-MVP\\n\\n- wybrać konkretne kanały które jesteśmy w stanie ocenić\\n- scrawlować\\n- sprawdzić parę pytań\\n\\n\\n*** MVP\\n-\\n\\n\\n*** toolz\\nlangchain / LLM Index\\n\\n***\\n\\n\\n*** Wizja\\n\\nFeedback przez pytania botów\\n\\nPlatforma ze ścieżkami uczenia\\n- ludzie projektują ścieżki\\n- dodają materiały\\n- dodają testy\\n\\nPersonalized learning\\n\\nTen gościu który bierze zapytania ludzi\\n\\n\\n\\n** GPT i bazy wiedzy\\n\\n\\n*** NAPIERDALAĆ DDD\\n\\n- odpowiadanie na pytania z prywatnej bazy\\n  korpo wiki\\n\\n- edtech - zadawanie pytań\\n\\n\\n** YT playlist summarizer/organizer\\n\\nŚciągnij dane z YT (jest taka funkcja google)\\n\\n\\n*** Eksploruj!\\n\\n- Słowa kluczowe (wordcloud)\\n\\n- wyszukiwanie po słowach\\n\\n- Redukcja wymiaru (ja to mogę zrobić w pół godziny)\\n  wizualizacje\\n\\n- klastrowanie\\n\\n  Tym można odpowiedzieć na pytanie czy inne grupowanie filmików niż zadane playlisty ma sens.\\n\\n  Można porównać klastrowanie do organizacji playlistami.\\n\\n- Automatyczne tagowanie - dajemy inne potencjalne nazwy playlist i grupujemy wg tego\\n\\n  Wpisujesz frazę np \"filmy historyczne\" i to wynajduje filmy z playlisty \"dokumentalne\" i nie tylko\\n\\n  To nie wiem czy realistycznie można zrobić na każdym kompie, ale sam bym chętnie sprawdził\\n\\n\\n\\n** Magisterka\\n\\n\\n** Noocosm\\n\\n\\n** Mlutil\\n\\n\\n** Yt transcription\\n\\n\\n** Unipipe\\n\\n\\n** Unsoyhackorg\\n\\n\\n** Stable diffusion\\n\\n\\n** Huggingface explorer\\n\\n\\n** Auto custodian\\n\\n\\n** Findkit\\n\\n\\n** Doclens\\n\\n\\n** Diffdiff\\n\\n*\\n\\n\\n* Praca\\n\\nWpierdalaj notatki że spotkań do inboxa\\n\\n\\n** Dialog manager\\n\\n\\n\\n\\nOdpowiedzialny też za zapisywanie z tym proxy\\n\\n<2023-03-10 pią>\\n\\n\\n** Ogarnąć burdel [66%]\\n\\n- [X] PR do rejestracji\\n- [ ] dokończyć serwis\\n- [X] testy czy coś w aptekach (???)\\n\\n\\n** przegadać z Wasylem serwisy\\n\\n\\n** Rozkmina z modelami\\n\\n\\n*** Multiserwis\\n- modele dosłownie współdzielą backbone\\n  backbone może być odrębnym serwisem?\\n  albo np heady mają kolejkę do ekstrakcji cech\\n\\n-\\n\\n\\n\\n** liczby\\n\\nchce się umówić 16 o 2\\n\\n\\n* Trans\\nKomunikator\\n\\nCzat dostarcza ktoś inny. Mamy crawler ofert\\n\\nPlan prosty - whatsapp - słabe bo czasochłonne itd\\n\\nIdealnie wbić się przez komunikator\\n\\nKonektor który pyka do iluś klientów i\\n\\nTrzeba określić ramy czasowe\\n\\nTool - SELENIUM\\n\\nJEZYK - polski?\\n\\n\\n\\n* What sucked\\n- komunikacja z Wasylem\\n- w aptekach trzeba było dać wysokopoziomowe readme\\n- pierdolenie się z compose zamiast faktyczna praca\\n [[id:cb28a7c7-5cbe-48f9-82c8-bed535f3a94d][build_systems]]\\n\\n\\n* Notes\\n\\n\\n* IN-PROGRESS Zrób notatki dla Magdy z Pythona\\n\\n\\n* Emacs\\n\\nEmacs ng/remacs - emacs z Rustem/Deno\\n\\nhttps://emacs-ng.github.io/emacs-ng/\\n\\n\\n* LLM Tools\\n\\n\\njak używać LLaM z pipeline huggingface?\\n\\nmake it work\\n\\n#+BEGIN_SRC python :session inbox.org  :exports both\\nfrom langchain import PromptTemplate, HuggingFaceHub, LLMChain\\n\\nmodel_name = \"decapoda-research/llama-7b-hf\"\\nllm=HuggingFacePipeline.from_model_id(\\n    task=\"text-generation\",\\n    model_id=\"models/llama-7b-hf\",\\n    model_kwargs={\"temperature\": 0, \"max_length\": 64},\\n    device=0,\\n)\\n#+END_SRC\\n\\nLangchain\\n\\nInspiration\\n- use LLM with google search\\n\\n\\n* Dziennik\\n\\n<2023-03-19 nie>\\n\\n\\n** DONE ogarnij czy lecimy langchainem czy llama index\\n\\n*** Langchain vs llama index\\n\\nLlama index has utils for chunking\\n\\nLangchain has stuff for indexing but its *documents* are supposed to be things to embed\\n\\nLLama index splits documents to chunks\\n\\n\\n*** How the fuck does tree index in llama index work?\\n\\n[[https://www.youtube.com/watch?v=9TxEQQyv9cE&t=613s][LLaMa index with huggingface]] - yt\\n\\n[[https://gpt-index.readthedocs.io/en/latest/guides/index_guide.html][LLaMaIndex - How Each Index Works - docs]]\\n\\nTree index seems to be slow\\n\\nMaybe we can tinker with it?\\n\\nMAYBE DOCUMENTS ARE SUPPOSED TO BE SINGLE LINES???\\n\\n\\n\\n*** Na razie jedziemy Langchain + Qdrant\\n\\n\\n\\n** DONE ogarnij \"SPC v t\" go to tangle\\n\\n\\n*** wydostań property z pliku orga\\n\\n\\n*** odpal\\n\\n\\n** DONE Podstawowy flow z ładowaniem dokumentów tekstowych\\n\\n\\n** DONE zaindeksuj docsy langchaina i llama index\\n\\n\\n\\n** org agenda żeby sie nie pogubić\\n\\n\\n** lamy i alpaki\\n[[id:a10eb046-98f3-409e-8ea1-0218e3bd1a4f][llms/alpaca]]\\n\\n\\n*** DONE Alpaka 13B\\n\\n\\n*** TODO hostowanie tym repo alpaki czy text-generation-webui?\\n\\n\\n*** TODO czy LLaMa 30B wejdzie ?\\n\\n*** TODO podepnij generowanie alpaką do ClearMLa\\n\\n\\n\\n*** finetuning\\n\\n\\n\\n\\n** DONE dodaj PDFa do llm_doc\\n<2023-03-31 pią>\\n\\n\\n** DONE on-disk qdrant w llm_doc\\n\\n\\n** DONE wyszukuj PDFa Rasy\\n\\n\\n** DONE Wprowadzenie do Rasy\\n\\n[[id:ba39ee5b-9e62-4637-8cf2-98cb8a950a8a][nlp/rasa]]\\n- jak działają stories\\n- feature, state i komponenty NLU\\n- jak wymusić determinizm checkpointami\\n\\n\\n** rasa - custom actions\\n\\n\\n\\n** LMQL[[id:760b983b-e4df-47e2-8832-0a7270c0183b][ llms/lmql]]\\n\\n\\n*** IN-PROGRESS how to use it for structured data\\n\\n\\n**** IN-PROGRESS tabular output\\n\\n\\n*** how to use it with a dialog manager?\\n\\n\\n*** +jakieś pokurwione akcje z RWKV+\\nchyba coś nie styka z tym tokenizatorem\\n\\n\\n*** DONE sync API\\n\\n\\n\\n**** DONE sync FastAPI\\n\\n\\n***** DONE podłączenie RWKV v 0.1\\n\\nna laptopie może zadziałać mniejsza wersja BlinkDL/rwkv-3-pile-169m\\nUWAGA: to może być inna wersja\\n\\n\\n\\n*** TODO podłączenie RWKV v 0.2\\nproblem:\\ndekodowanie RWKV działa trochę inaczej niż HF\\nto wszystko nie do końca działa\\n\\n\\n\\n\\n** LLM generation\\n[[id:a862af1c-b442-4da6-9b47-09adc42cbba6][llms/generation]]\\n\\n[[id:35740f44-515a-4bf6-bfd1-cd949e827913][llms/retrieval_augmented]]\\n\\n** co teraz?\\n- in context learning (mamy)\\n- retrieval augmented generation?\\n  pociągnij\\n\\n[[id:64146b02-3dc3-4e33-a570-716191d92f91][mgr/experiments]]\\n\\n** <2023-04-11 wto>\\nmongo - Magda to zrobi\\ninterfejs w gradio dla medteamu\\n- docker na macu\\n\\n** obczaj listę od Wrony\\n\\n[[id:fad664b1-7ae9-4c7e-b2b0-87298b88d8e4][conversational_llms]]\\n\\n\\n*** OpenAssistant\\n*English supervised-fine-tuning (SFT)*\\n\\n\\n*** LiT-LLaMa\\nNie ma wag\\n\\n\\n*** Pythia\\nSam LM (w sumie chyba OpenAssistant na nim bazuje)\\n\\n\\n*** Flan-UL2\\nsam LM, rozmiar kontekstu = 2k\\n\\n\\n*** Dolly\\ndolly-v1-6b is intended exclusively for research purposes and is not licensed for commercial use.\\n\\n\\n*** Cerebras-GPT\\nsam LM\\n\\n\\n*** GeoV\\nsam LM\\n\\n\\n** ocb z tymi pejperami od Pjotera\\nPodejście do LLMów jest takie\\n\\nW jednym paperze jest konwersacyjny model na transkryptach\\n- morał jest taki że jak się dotrenuje do specyficznych danych medycznych to wyniki się sporo poprawiają\\n-\\n\\n\\n\\n** pogadanka z Filipem\\n\\nADMIN to ktoś kto odpala apkę gradio\\n\\n\\n*** roadmapa wywiadu medycznego\\n\\ntrzeba obgadać z medteamem\\n- wymagania\\n- jakie dane dadzą\\n\\nile będzie pierdolenia z zapięciem modeli\\nmało\\n\\n\\n*** NER - skupiamy się na  nim\\n- modele huggingface - standardowy NER\\n- wizualizacje NERów itd\\n  Bartek napisał kodzik który pokazuje ze streamlita\\n\\n\\n*** Poza tym\\n- sprawy\\n- relacje\\n\\n\\n*** V2\\n\\nworkflow - jak będzie wyglądał pipeline\\n2 nurty:\\n\\n**** platforma dla medteamu\\n- wejście - transkrypt\\n-\\n\\n\\n**** wersja produkcyjna\\n- ASR\\n\\n- nasze systemy MLowe\\n- bot\\n- co na wyjściu?\\n[[id:a611adc5-215d-44a8-aadd-b98c46a3a1ec][wywiad_medyczny_flow]]\\n\\n***** architektura\\n\\n****** ASR od Wasyla\\n\\n****** serwisy MLowe (Platoniusz)\\n\\n****** dialog manager <- TUTAJ NACISK\\n\\n****** zewnętrzne dane\\n\\n****** MLOpsy\\n\\n\\n** DONE popraw apkę gradio\\n\\n\\n*** zaszyfrowane credentiale\\n- dodaj usera (może cały config?) do logowania\\n\\n*** tiktoken\\n\\n\\n** IN-PROGRESS rozstaw na lambdzie czy gdzieś jakiegoś LLMa\\n\\n\\n*** IN-PROGRESS FastAPI\\n\\n\\n**** DONE schemat OpenAPI\\n\\n\\n**** IN-PROGRESS aplikacja FastAPI\\n\\n\\n***** ciekawostka jak w LMQLu pykają po logity\\n\\n\\n**** ładowanie LLMa\\n\\n\\n***** który LLM?\\n\\n\\n****** jakiś mały RWKV\\n\\n\\n****** model z huggingface\\n\\n\\n****** LLaMa?\\n\\n\\n\\n**** implementacja endpointów\\n\\n\\n\\n\\n** TODO historia promptowania\\n\\n** TODO Artykuł o LMOps\\n\\n** TODO Bajery LLaMaIndex\\n\\n** TODO UDAPDR - updating embeddings\\n\\n\\n** [[id:1cafd8f7-cd85-456a-a2e5-a1011edc00e6][openassistant]]\\ntrochę\\xa0bajzel mają z tymi portami\\nw sumie to kij z tym bo mnie interesuje inference\\n\\n\\n\\n*** memory\\ndoes it use any vectordb???\\nhow to integrate if it doesn\\'t use one?\\n\\n\\n*** Plugins\\nYK cośtam nawijał o pluginach\\n\\n\\n** emacs\\n- linkowanie do pliku\\n- org-ai\\n\\n\\n\\n** Papery z IR\\n\\n[[id:36515f95-100f-4dbb-bf90-cc88ee76282e][prompt_tricks]]\\n\\n\\n** DONE LLM.int8\\n   DEADLINE: <2023-04-21 Fri>\\nTL;DR\\nkwantyzacja modeli do inferencji\\n\\n kwantyzacje rozwalają cechy outliery które mają duże wartości więc one są kwantyzowane osobno\\n\\n** TODO Godot - dodo\\nhttps://github.com/minosvasilias/godot-dodo\\n\\nLLMy na kodzie\\n\\n\\n** notes medsi\\n<2023-04-30 nie>\\n[[id:f98ad094-a9ea-4a11-ac74-f0441bf26273][notehelper]]\\n\\n[[id:d4c9cf4c-d352-4e5e-9ed1-669cacff5902][question_answering]]\\n\\n\\n** TODO HuggingGPT/AutoGPT\\n   DEADLINE: <2023-05-09 wto>\\n\\n\\n** inby z logowaniem w gradio\\n\\n\\n** deploy LMa\\n\\n\\n** [[id:0d15b026-1607-4315-90e4-2892d32475a8][wm/mvp]]\\n\\n\\n** medsi inbox migrated to [[id:583ab1be-f878-46fa-b8ba-b8eefbd76ddb][medsi]]\\n\\n\\n** mgr\\n<2023-05-18 czw>\\n\\n\\n*** write down results of the experiment for couple of models\\n- rwkv\\n- pythia from openassistant\\n- some bare text generation models\\n\\n\\n*** constraining text generation\\n\\n\\n\\n** mgr spotkanie maj\\n<2023-05-19 pią>\\n:PROPERTIES:\\n:ID:       f90d67a3-89cd-4b5a-8068-c82c4ee1a565\\n:END:\\n\\nMorał: wracamy do poprzedniego podejścia.\\n\\nLiczymy metryki ewaluacyjne i porównujemy do wyników wyszukiwania\\n\\nDODATKOWO potem oceniamy ludźmi\\n\\n\\n*** TODO kontrolowana generacja\\nna razie wpiąć tokeny z tasków do rellma\\n\\n\\n*** uśrednianie promptów\\n\\n\\n*** zapisać narrację\\n- mamy sztuczny task\\n- możemy wyliczyć metryki IR\\n- możemy porównać pipeline pod kątem metryk do document expansion\\n- proponujemy mały eksperyment żeby sprawdzić czy powyższe metryki nie są z czapy\\n\\n\\n\\n\\n\\n* Spotkanie\\nJak dużo tych tabel?\\n\\nJak w ogóle oceniać czy LLMy działają?\\n\\nCzy da się sterować LLMa?\\n\\nJak duże znaczenie ma rozmiar kontekstu?\\n\\n\\nOdmiana przez NLG? Jak mamy konkretne frazy to rule-based spoko\\n\\nTu ta normalizacja nie będzie dużym problemem?\\n\\nLLMy - będziemy porównywać z podejściem NERowym\\nNa razie równolegle będą 2 tabele\\n\\nLLMy w praktyce - na pewno będą do adnotacji\\n\\nJaką część projektu researchowego trzeba zrobić bez LLMow albo jest niepotrzebna dla LLMow?\\n\\nLLMy w adnotacji dla NERa? Jak wygląda ograniczanie GPT do ilus klas?\\n\\nCo w ogóle z finetuningiem dla tabelek? To powinno być łatwe\\n\\n\\n2 wersje:\\n- optymalizacja promptow\\n\\n\\nPodejścia:\\n- najpierw jedną klasę\\n- wszystkie klasy\\n- potem próbujemy łączyc klasy\\n\\nMVP\\n- medteam wrzuca prompty\\n- wychodzimy\\n\\nMapowanie wyjścia z LLMow na ontologię\\n\\nPierszy strzał\\n- patrzymy na wyjścia tabelkowe\\n- dla danego promptu i wywiadów podaje wyjścia\\n\\n\\n- jak są wybierane dane?\\n\\n\\nTabelki do wywiadu\\n\\n* Magisterka\\n\\n\\n** Pomysły\\n\\n- użyj mechanizmu uwagi do podsumowania\\n- użyj\\n\\n\\n** DONE Użyj hierarchicznej struktury do wyszukiwania\\n   DEADLINE: <2023-05-03 śro>\\nW LLaMaIndex jest o tworzeniu hierarchicznych indeksów\\n\\nMoze LLMy korzystając z naszej grafowej struktury będą lepiej wyszukiwać?\\n\\n\\n** Dziennik\\n\\n\\n*** <2023-03-21 wto>\\n\\n\\n**** promptsource jest z czapy\\n\\n\\n*** PEFT\\n    DEADLINE: <2023-05-02 wto>\\n\\n\\n**** TL;DR\\n\\n- use LORA\\n- use prefix tuning\\n- P-tuning\\n- prompt tuning\\n\\n\\n*** LLM Data generation [0%]\\n- text-generation-webui [100%]\\n\\n  - [X] zaindeksuj projekt\\n    jaki model do kodu? Ten MPNet styknie?\\n  - [X] załaduj model\\n\\n  - [X] ogarnij tokenizację\\n\\n  - [X] ogarnij czy to działa batchowo albo czy da się to zrobić\\n    - jest problem z nowym tokenem\\n\\n- [ ] jak działają prompty\\n  - [ ] czy da się zapiąć templating\\n\\n\\n*** CZY JA SIĘ NIE PAŁUJĘ NIEPOTRZEBNIE?\\nCZEGO MI TRZEBA ŻEBY LLM POMÓGŁ MI PISAĆ KOD?\\n\\nTeraz zapierdalam żeby dodać\\xa0indeksowanie\\njak będzie indeksowanie to można podpiąć LLaMę\\n\\n\\n**** TODO dodać indeksowanie do lokalnej bazy\\n\\n\\n*** DONE RWKV-7B\\ndo bani\\n\\n\\n*** Promptowanie LLaMy\\n<2023-03-26 nie>\\n\\n\\n**** DONE lepsze promptinfo\\n\\n\\n\\n**** DONE lepsze prompty\\n\\n\\ndla danego repo weź repo prefiksu z podobnymi taskami\\n\\n\\n***** UWAGA\\nto odpada dla testowania, tylko przydatne do generowania danych treningowych\\n\\n\\n**** DONE sprawdź wygenerowane tagi - na ile mamy halucynacje\\n\\n\\n***** jak to oceniać [100%]\\n- [X] sprawdzaj na ile te tokeny w ogóle są tokenami z tasków\\n- [X] sprawdzaj na ile słowa są w taskach\\n\\n\\n\\n**** Czyszczenie tasków\\nwywal 3d itd\\n\\n\\n**** fuzzy matching tasków\\n\\n\\n**** [[id:34da7672-3542-42ba-b945-a3caa178fb26][mgr/data_generation_review]]\\n<2023-03-27 pon>\\n\\n\\n**** Promptify\\n\\n\\n***** promptify i tabelki <2023-03-28 wto>\\n\\n\\n****** TODO przepisz prompt z tekstu\\n\\n\\n****** DONE napisz kod który formatuje PromptInfo\\n\\n\\n\\n**** DONE async do pykania do API\\n#+BEGIN_SRC python :session inbox.org  :exports both\\ndef run_async_on_files(func, files_list):\\n    \"\"\"\\n    input:\\n    - function `func`\\n    - list of files to be processed by `func`\\n    output:\\n    - list of files processed by `func`\\n    - list of files on which `func` failed\\n\\n    behavior:\\n    - `func` should be called asynchronously\\n    - there should be a progress bar that tracks how many files were processed\\n\"\"\"\\n\\n\\n#+END_SRC\\n\\n\\n\\n**** mgr ciąg dalszy\\n\\n[[id:5412a751-47eb-4843-a431-d08e1cff3f2d][mgr/prompts]]\\n[[id:8cfb68cf-bd41-414a-9a63-e2408240d25c][mgr/data_generation_ideas]]\\n\\n\\n**** <2023-04-05 śro>\\ninterfejs do LLMów\\n\\n**** <2023-04-06 czw>\\n\\n\\n*** obczaj wystawianie LLaMy/RWKV na Ruście\\n<2023-04-08 sob >\\n\\n\\n\\n*** produktywny dzień\\n<2023-05-03 śro>\\n\\nZarzuciłem 20mg i jest spoko\\n\\n\\n**** pomysł [[id:ee639bd3-1841-4fd1-a84a-1047db49d6dd][smartdiff]]\\n\\n- lepszy stackshare/Sourceforge\\n- funkcjonalność z wykorzystaniem magisterki\\n- tłumaczenie wyszukiwania\\n\\n\\n***** TODO Value proposition\\n\\n\\n****** Compare products in depth\\n\\n\\n****** Compare products in context\\n\\n\\n**** scrapowanie danych o opcjach\\n\\n[[id:54f7d50e-5d8b-41c6-9e1a-91624c7a972f][options_data_api]]\\n\\n\\n\\n**** magisterka\\n\\n\\n\\n\\n**** LMSYS org\\n\\n\\n\\n\\n*** NEW ITEM HERE\\n\\n\\n** Ewaluacja\\na co jakby zrobić historyjkę jakich rzeczy spróbowaliśmy?\\n\\nW sensie w jaki sposób można mierzyć zadania użyteczne dla wyszukiwania\\n- generujemy np różne labelki\\n  używamy InParsa, promptagatora czy whatnot\\n- mierzymy wyniki patrząc na wyszukiwanie\\n- mierzymy na ile model zmyśla\\n- jedziemy BLEU/BERTScore\\n- jeszcze jakaś jedna metryka do wymyślenia\\n- deliverable to toolkit typu wstaw sobie klienta do LLMa i możesz wyliczyć te różne metryki\\n\\n[[id:81628938-1275-44e4-888f-427f047e4df4][mgr/new_approach]]\\n\\n** LLaMa RS\\n[[id:165279b9-aaaf-4265-a075-4080f1192ee5][llms/rust]]\\n\\nogólnie za wolne\\n\\n\\n** Retrieval plugins\\n\\n[[id:e3f417b8-e66a-4db7-a08f-788950d52b17][llms/plugins]]\\n\\n\\n** Mgr\\n\\nQueries and idea how to set up retrieval\\n[[id:d6b24e1d-ee70-4d57-b5bc-78149feb4802][mgr/query_data_construction]]\\n\\numbertobot for indexing stuff\\n\\n[[id:8be4fc30-bac3-4558-b6de-27e7fab1cbd9][umbertobot]]\\n\\n[[id:4b2195e5-4602-4966-971f-0320a373ac30][papers/instructor_embedding]]\\n\\n\\n\\n\\n** Mgr\\n\\nspotkanie\\n\\n\\n* Notatki\\n\\nrobisz to źle\\n\\n- do inboxa pakujesz na pałę\\n- po ogarnięciu inboxa kasujesz\\n\\n\\n\\n* Disruptive innovation\\n\\n** Disruptive innovation\\n- większość dużych firm ma np 20% rynku i są na wypłaszczeniu krzywej S\\n- nie stać ich na odejście od optymalizacji lokalnej bo klienci będą niezadowoleni i zje ich konkurencja\\n\\n\\n** Strategia (na razie musisz się rozeznać)\\n- różne procesy biznesowe dla różnych produktów/projektów\\n- ile R&D\\n\\n\\n** Decyzje padające przed podjęciem decyzji\\n- dzisiejsze metryki są znormalizowane\\n- normalizacja pomaga porównywać rożne'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '323',\n",
       "  '_score': 5.7719126,\n",
       "  '_source': {'org_id': 'a862af1c-b442-4da6-9b47-09adc42cbba6',\n",
       "   'file_name': '20230410112006-llms_generation',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms/generation\\n\\nllms\\n',\n",
       "   'links': ['6e74849f-6bb9-4ce7-aba6-2ae660155906',\n",
       "    '9d2478d7-92a9-4e7a-ad04-66d85bdd52a0',\n",
       "    'a8879f53-1895-489a-8828-130cda0c1e12'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       a862af1c-b442-4da6-9b47-09adc42cbba6\\n:END:\\n#+title: llms/generation\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\n\\n* Speed\\n[[id:6e74849f-6bb9-4ce7-aba6-2ae660155906][llms/speed]]\\n\\n\\n* alternatives to greedy/beam search\\n\\n[[id:9d2478d7-92a9-4e7a-ad04-66d85bdd52a0][llm/knowledge_index]]\\n\\n[[id:a8879f53-1895-489a-8828-130cda0c1e12][ml/llms_biznes]]\\n\\n\\n\\n\\n\\n* Evaluation - general\\n\\n\\n\\n* Evaluating verifiability\\n\\n[[cite:&liu23_evaluat_verif_gener_searc_engin]]'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '157',\n",
       "  '_score': 5.658792,\n",
       "  '_source': {'org_id': '45eb5f87-bfea-4f5a-afd2-bc78a543ec21',\n",
       "   'file_name': '20230630163909-small_lm_hypothesis',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: small_lm_hypothesis\\n\\nllms\\n\\nllms/constrained_generation\\n',\n",
       "   'links': [],\n",
       "   'text': ':PROPERTIES:\\n:ID:       45eb5f87-bfea-4f5a-afd2-bc78a543ec21\\n:END:\\n#+title: small_lm_hypothesis\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\n[[id:97379691-82f0-4fcd-a521-2ab3aeacda8a][llms/constrained_generation]]\\n\\n\\n* Context\\n\\nThere is a huge gap between capabilities of LLMs like GPT-4 or Falcon and smaller 3-6B models.\\n\\nFor tasks with /structured output/ like classification/NER there is no need to use a full-blown LM\\n\\n\\n** Hypothesis\\n\\nThe gap between capabilities of LLMs and tiny LMs for simple /structured output/ tasks will be dramatically lower compared to general capabilities'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '8',\n",
       "  '_score': 5.4941893,\n",
       "  '_source': {'org_id': '87ace112-d9da-488b-9b2b-0d36983aec57',\n",
       "   'file_name': '20230405202510-lmops',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: lmops\\n\\nllms\\n',\n",
       "   'links': ['53e46f10-1686-41a3-8a13-7daee352bd98',\n",
       "    '8d34184b-9d9a-438b-bac1-ad1ac199e4b4',\n",
       "    '4d815aca-7609-44b9-83b8-312200021e09',\n",
       "    '8328b56f-56d2-4aab-a938-24dacd2a5467',\n",
       "    '4ac9dd90-80c1-4306-82fd-cc914e40e0ba',\n",
       "    '264960a4-0107-428f-9a79-fa799c6bff77'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       87ace112-d9da-488b-9b2b-0d36983aec57\\n:END:\\n#+title: lmops\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n\\n\\n* Summary\\n\\nTools for managing applications with LMs\\n\\n\\n* Reading list\\n\\n[[id:53e46f10-1686-41a3-8a13-7daee352bd98][article/huyen_building_llm_app]]\\n\\nhttps://www.latent.space/p/bryan-bischof\\n\\n\\n* Video\\n\\n[[https://www.youtube.com/watch?v=Fquj2u7ay40&feature=youtu.be][LLMOps (LLM Bootcamp)]]\\n\\n\\n* Experiment versioning\\n\\n<2023-05-15 pon>\\n\\nUnfortunately there is no standard toolset.\\n\\nCurrently we use approach [[id:8d34184b-9d9a-438b-bac1-ad1ac199e4b4][lmops/gsheets]]\\n\\n\\n** Key issues\\n\\nThe most important thing is to have a systematic way to compare models and prompts\\n\\nneed to version:\\n- prompts\\n- generated results\\n\\n\\n* Data drift\\n[[id:4d815aca-7609-44b9-83b8-312200021e09][nlp_drift]]\\n\\n\\n* Tools\\n\\n\\n** Simple tools\\n\\n\\n*** [[id:8328b56f-56d2-4aab-a938-24dacd2a5467][demonstrate_search_predict]]\\n\\n\\n*** [[id:4ac9dd90-80c1-4306-82fd-cc914e40e0ba][minichain]]\\n\\n\\n*** [[id:264960a4-0107-428f-9a79-fa799c6bff77][nemo_guardrails]]\\n\\n\\n** Full-blown Ops tools\\n\\n\\n*** Jarvis\\n\\n\\n**** Use text model to choose HF models for specific tasks\\n\\n\\n*** E2B\\n- UI for low code?\\n\\n\\n*** Jaseci\\n\\nWhole new approach\\n\\nUsed for end2end generation'}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '152',\n",
       "  '_score': 5.369691,\n",
       "  '_source': {'org_id': 'cb7a0136-b6d3-4032-9ab7-4d05abe4b218',\n",
       "   'file_name': '20231204125806-llms_llm_os',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: llms/llm_os\\n\\n',\n",
       "   'links': [],\n",
       "   'text': \":PROPERTIES:\\n:ID:       cb7a0136-b6d3-4032-9ab7-4d05abe4b218\\n:END:\\n#+title: llms/llm_os\\n\\n\\n\\n* [[https://huggingface.co/blog/shivance/illustrated-llm-os][Illustrated LLM OS: An Implementational Perspective]]\\n\\nKarpathy's idea is to use LLM agent as a CLI tool\\n\\n#+BEGIN_QUOTE\\nA novel approach involves injecting state machines into the decoding process, enabling real-time code execution and interaction.\\n#+END_QUOTE\\n\\n\\n** Ideas\\n\\n\\n*** Execution tuning\\n\\nRL on behavior\\n\\n\\n*** State machines\\n\\n\\n*** Constrained decoding\"}},\n",
       " {'_index': 'org_roam',\n",
       "  '_type': '_doc',\n",
       "  '_id': '311',\n",
       "  '_score': 5.1836967,\n",
       "  '_source': {'org_id': '3205458c-af08-4a52-a65c-d8aab9ffdbcf',\n",
       "   'file_name': '20230421110352-medsi_llm',\n",
       "   'heading': '',\n",
       "   'level': 0,\n",
       "   'body': '#+title: medsi/llm\\n\\nllms\\nmedsi\\n\\nqa/medsi\\n',\n",
       "   'links': ['c505c9b8-e486-4bb1-ae7a-4a16cba75ba2',\n",
       "    'bc7d9509-42ba-4d34-8c38-1b285abf4fd4',\n",
       "    'fcd8718f-40d5-4f21-9b26-d8d758284681',\n",
       "    '0b857b7f-9b66-4618-a374-4ebff68fee8b',\n",
       "    'aece58c3-a44e-4d09-a5f7-855a6a359277'],\n",
       "   'text': ':PROPERTIES:\\n:ID:       3205458c-af08-4a52-a65c-d8aab9ffdbcf\\n:END:\\n#+title: medsi/llm\\n\\n[[id:dc4a0d36-8d07-4a6b-87f5-3f7cfb6e283b][llms]]\\n[[id:583ab1be-f878-46fa-b8ba-b8eefbd76ddb][medsi]]\\n\\n[[id:af8a195e-d28e-4c30-8de2-ca86feb518ce][qa/medsi]]\\n\\n\\n* Cotygodniowe spotkania syncujące\\n\\n\\n** Tendencje\\n\\n\\n*** UI\\n\\n\\n*** DSL\\n\\n\\n*** Agent/kolejki\\nna razie olać\\n\\n\\n*** Finetuning/few shot\\nintegracja z MLOpsem\\n\\n\\n*** Kontrolowana generacja\\n\\n*** Kwantyzacja\\n\\n\\n** Spotkanie <2023-05-12 pią>\\n\\n\\n*** minimalizacja korzystania z LMów\\n:PROPERTIES:\\n:ID:       bc7d9509-42ba-4d34-8c38-1b285abf4fd4\\n:END:\\n\\n[[id:c505c9b8-e486-4bb1-ae7a-4a16cba75ba2][Frugal GPT]]\\n[[id:bc7d9509-42ba-4d34-8c38-1b285abf4fd4][minimalizacja korzystania z LMów]]\\n\\n\\n*** Wasyl wystawił OpenAssistanta\\nmożna powtykać różne modele z HF\\n\\n\\n*** podsumowania\\n[[id:fcd8718f-40d5-4f21-9b26-d8d758284681][llama_index]]\\n\\n**** llamaindex\\n\\n\\n**** ekstraktywne czy abstraktywne?\\n\\n\\n*** trzeba ogarnąć dane do LLMów tabelkowych\\n[[id:0b857b7f-9b66-4618-a374-4ebff68fee8b][żelazne prompty]]\\n\\n\\n** Spotkanie <2023-05-19 pią>\\n\\n\\n*** OpenAssistant\\n\\nW OAsst niby nie powinno być potrzeby w UI dodawania tych tokenów <prompt> itd\\n\\nMed team na razie przed wpięciem do UI będzie jechał po swaggerze\\n\\n\\n*** Adaptery do gotowych modeli\\n\\n\\n**** Wymuszanie formatu wyjścia\\n\\nrellm\\n\\n\\n**** Ensembling promptów\\n\\nJakie narzęzie?\\n\\n\\n\\n* Zadania\\n\\n\\n** TODO przepuść batchowo prompty na OpenAssistancie\\n\\nmedteam wybierze ważne i interesujące prompty\\n\\n\\n** dockery do trenowania modeli\\n\\n\\n** alternatywne LLMy\\n- RWKV\\n- LLaMa na Ruście\\n\\n\\n* Modele do medicala\\n\\n\\n** Pythia\\n\\n\\n** Modele typowo na medicalu\\n\\n\\n** Poprawianie\\n\\n\\n\\n* Pierwsza wersja LLMów do tabelek/NERa\\n\\n[[id:aece58c3-a44e-4d09-a5f7-855a6a359277][medsi/llm_mvp]]'}}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.search(index=\"org_roam\", body={\"query\": llm_query})[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae49b5a4-07bc-4022-8bd7-00cedcf9ccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'github_search': {'mappings': {'properties': {'refresh': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'title': {'type': 'text', 'analyzer': 'english'}, 'txt': {'type': 'text', 'analyzer': 'english'}}}}, 'org_roam_nodes': {'mappings': {'properties': {'body': {'type': 'keyword'}, 'file_name': {'type': 'keyword'}, 'heading': {'type': 'keyword'}, 'level': {'type': 'long'}, 'links': {'type': 'keyword'}, 'org_id': {'type': 'keyword'}, 'text': {'type': 'text', 'fields': {'keyword': {'type': 'keyword'}}}}}}, 'org_roam': {'mappings': {'properties': {'body': {'type': 'text'}, 'file_name': {'type': 'keyword'}, 'heading': {'type': 'keyword'}, 'level': {'type': 'long'}, 'links': {'type': 'keyword'}, 'org_id': {'type': 'keyword'}, 'text': {'type': 'text'}}}}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.indices.get_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6417697-5983-417d-918d-fc8b11ba74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(roam_elastic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce91a1-7b62-4800-a73d-97198e7640cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "roam_elastic_df.es_match(\"pragmatics\", columns=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536143fc-cf3c-4bf5-ac96-d6f89a2b3e7a",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160db48-933f-43ed-85af-fb4090669db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = roam_elastic_df[\"text\"].to_pandas().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60b801-f15a-4bc1-89c2-35bf3c09be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, feature_extraction, pipeline\n",
    "\n",
    "n_topics = 25\n",
    "lda = decomposition.LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "\n",
    "lda_pipeline = pipeline.make_pipeline(\n",
    "    feature_extraction.text.CountVectorizer(),\n",
    "    lda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d50ab1-fdc8-4c9a-af83-8c0c844cce05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc0e5d-ed9b-4f0c-8f64-08756e64db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lda_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcabe01-3f0a-405c-b633-6f2bdcdc6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable\n",
    "\n",
    "class TopicModeler(BaseModel):\n",
    "    tm_pipeline: pipeline.Pipeline\n",
    "    text_col: str\n",
    "    preprocess_texts: Callable[pd.Series, pd.Series]\n",
    "\n",
    "    @classmethod\n",
    "    def init_unfitted(cls, make_vectorizer, make_topic_modeler, n_topics, text_col, vectorizer_kwargs, tm_kwargs, preprocess_texts):\n",
    "        tm_kwargs[\"n_components\"] = n_topics\n",
    "        tm_pipeline = pipeline.make_pipeline(make_vectorizer(**vectorizer_kwargs), make_topic_modeler(**tm_kwargs))\n",
    "        return TopicModeler(tm_pipeline=tm_pipeline, text_col=text_col, preprocess_texts=preprocess_texts)\n",
    "\n",
    "    @classmethod\n",
    "    def init(cls, texts_df, make_vectorizer, make_topic_modeler, n_topics, text_col=\"text\", vectorizer_kwargs={}, tm_kwargs={}, preprocess_texts=lambda texts: texts):\n",
    "        tm = cls.init_unfitted(make_vectorizer, make_topic_modeler, n_topics, text_col, vectorizer_kwargs, tm_kwargs, preprocess_texts)\n",
    "        tm.tm_pipeline.fit(preprocess_texts(texts_df[text_col]))\n",
    "        return tm\n",
    "    \n",
    "    def get_topic_representatives(self, texts_df, topic_idx, agg_by=None, topk=5):\n",
    "        topic_scores = self.tm_pipeline.transform(texts_df[self.text_col])[:,topic_idx]\n",
    "        top_idxs = topic_scores.argsort()[::-1][:topk]\n",
    "        results_df = texts_df.iloc[top_idxs]\n",
    "        return results_df.assign(topic_score=topic_scores[top_idxs])\n",
    "\n",
    "    def get_top_topic_words(self, topk=25):\n",
    "        return self.features[self.topic_loadings.argsort(axis=1)[:,::-1][:,:topk]]\n",
    "\n",
    "    def get_topics(self, texts_df):\n",
    "        preprocessed_texts = self.preprocess_texts(texts_df[self.text_col])\n",
    "        return pd.Series(self.tm_pipeline.transform(preprocessed_texts).argmax(axis=1))\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        (_, vectorizer) = self.tm_pipeline.steps[0]\n",
    "        return vectorizer.get_feature_names_out()\n",
    "\n",
    "    @property\n",
    "    def topic_loadings(self):\n",
    "        (_, tm) = self.tm_pipeline.steps[-1]\n",
    "        return tm.components_\n",
    "        \n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    @property\n",
    "    def n_topics(self):\n",
    "        [(_, tm)] = self.tm_pipeline.steps[-1:]\n",
    "        return tm.n_components\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee94e4-fc94-4c51-9d74-cdbabf4cbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_file_contents = roam_df.groupby(\"file_name\").apply(lambda df: \"\\n\".join(df[\"text\"]))\n",
    "org_file_roam_df = pd.DataFrame(org_file_contents)\n",
    "org_file_roam_df.columns = [\"text\"]\n",
    "org_file_roam_df = org_file_roam_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013ea8d-2e7d-4026-9497-f6722014341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 25\n",
    "\n",
    "used_stop_words = stop_words.get_stop_words(\"en\") + stop_words.get_stop_words(\"pl\")\n",
    "vectorizer_kwargs={\"min_df\": 5, \"binary\": True, \"stop_words\": used_stop_words}\n",
    "nmf_kwargs = {\"alpha_W\": 1e-4, \"l1_ratio\": 0.0, \"beta_loss\": \"kullback-leibler\"}\n",
    "\n",
    "\n",
    "def preprocess_snakecase(texts):\n",
    "    return texts.str.replace(\"_\", \" \").str.replace(r\" \\d+ |\\d{3,}\", \" NUMBER \")\n",
    "\n",
    "\n",
    "lda_tm = TopicModeler.init(\n",
    "    org_file_roam_df,\n",
    "    n_topics=n_topics,\n",
    "    make_vectorizer=feature_extraction.text.CountVectorizer,\n",
    "    make_topic_modeler=decomposition.LatentDirichletAllocation,\n",
    "    vectorizer_kwargs=vectorizer_kwargs,\n",
    "    preprocess_texts=preprocess_snakecase\n",
    ")\n",
    "\n",
    "nmf_tm = TopicModeler.init(\n",
    "    org_file_roam_df,\n",
    "    n_topics=n_topics,\n",
    "    make_vectorizer=feature_extraction.text.TfidfVectorizer,\n",
    "    vectorizer_kwargs=vectorizer_kwargs,\n",
    "    make_topic_modeler=decomposition.NMF,\n",
    "    preprocess_texts=preprocess_snakecase\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebe4ba-f6be-40ae-a89b-42cd0edeee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tm.get_topics(roam_df).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba98f6-b252-4583-90a7-14578247404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.get_topics(roam_df).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fcb9b-b0b4-48c2-a0ab-ce0b42b82c0d",
   "metadata": {},
   "source": [
    "## Guessing good parameters for NMF\n",
    "\n",
    "We optimize for the smallest size of biggest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f39c4-f856-481c-8740-1ad777be4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    nmf_kwargs = {\n",
    "        \"alpha_W\": trial.suggest_loguniform(\"alpha_W\", 1e-6, 0.1),\n",
    "        \"beta_loss\": trial.suggest_categorical(\"beta_loss\", [\"frobenius\", \"kullback-leibler\"]),\n",
    "        \"solver\": \"mu\"\n",
    "    }\n",
    "    \n",
    "    nmf_tm = TopicModeler.init(\n",
    "        org_file_roam_df,\n",
    "        n_topics=n_topics,\n",
    "        make_vectorizer=feature_extraction.text.TfidfVectorizer,\n",
    "        vectorizer_kwargs=vectorizer_kwargs,\n",
    "        make_topic_modeler=decomposition.NMF,\n",
    "        tm_kwargs=nmf_kwargs,\n",
    "        preprocess_texts=preprocess_snakecase\n",
    "    )\n",
    "    return nmf_tm.get_topics(roam_df).value_counts().max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c9e80-3e64-4826-b22e-567fef09c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff402e-4d75-47cb-af22-3457eeeed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pd.DataFrame.from_records([{**trial.params, \"value\": trial.value} for trial in study.get_trials()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594107f-6962-4466-a756-b863f22db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df[(trials_df[\"value\"] < 1000) & (trials_df[\"beta_loss\"] == \"frobenius\")].plot.scatter(\"alpha_W\", \"value\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253bd1e-fc66-462d-b955-9ac3c1d42417",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df[(trials_df[\"value\"] < 1000) & (trials_df[\"beta_loss\"] == \"kullback-leibler\")].plot.scatter(\"alpha_W\", \"value\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914d5c7-0bee-4a4e-a6da-8264cec5bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.groupby(\"beta_loss\").agg({\"value\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb272a2c-925c-4396-bdf8-653bed55f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.tm_pipeline.transform(roam_df[\"text\"]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87777e4-ff01-48f7-bd97-408baf657ca3",
   "metadata": {},
   "source": [
    "# Topic representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8988c-8a6f-4e3c-b978-9e54c95bc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tm.get_topic_representatives(roam_df, 23, topk=100).groupby([\"file_name\"]).agg({\"topic_score\": \"mean\"}).sort_values(\"topic_score\", ascending=False).iloc[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89821a89-d964-4a92-8c3d-67c7ff79739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.get_topic_representatives(roam_df, 1, topk=100).groupby([\"file_name\"]).agg({\"topic_score\": \"mean\"}).sort_values(\"topic_score\", ascending=False).iloc[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0b98a-af82-4c53-aca5-dd05d31b91a8",
   "metadata": {},
   "source": [
    "## Top words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ff146-0a1b-48d2-92f8-c431ddf013a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.get_top_topic_words()[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dddce3-922c-44d1-92ed-832ac6e47fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tm.get_top_topic_words()[:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37a0ab-de96-4dfb-b3da-aacc43179fae",
   "metadata": {},
   "source": [
    "## BERTopic\n",
    "\n",
    "small - runs on org nodes\n",
    "big - runs on whole files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18f6bb-7f99-4380-866d-51647a560cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4111cbd-ce76-4425-b6ce-8a9e0113e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_topic_representation_model = bertopic.representation.MaximalMarginalRelevance(diversity=0.3)\n",
    "keybert_topic_representation_model = bertopic.representation.KeyBERTInspired()\n",
    "\n",
    "bertopic_models = {}\n",
    "bertopic_models[\"big_kw\"] = bertopic.BERTopic(language=\"multilingual\", representation_model=keybert_topic_representation_model, nr_topics=50, min_topic_size=5)\n",
    "bertopic_models[\"big_mmr\"] = bertopic.BERTopic(language=\"multilingual\", representation_model=mmr_topic_representation_model, nr_topics=50, min_topic_size=5)\n",
    "bertopic_models[\"small_kw\"] = bertopic.BERTopic(language=\"multilingual\", representation_model=keybert_topic_representation_model, nr_topics=50, min_topic_size=25)\n",
    "bertopic_models[\"small_mmr\"] = bertopic.BERTopic(language=\"multilingual\", representation_model=mmr_topic_representation_model, nr_topics=50, min_topic_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877e46-7fe6-403c-9e7b-30568219c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bertopic(bertopic_model):\n",
    "    for topic in sorted(bertopic_model.topic_sizes_.keys()):\n",
    "        print(f\"topic {topic}\")\n",
    "        topic_info = bertopic_model.get_topic_info(topic).iloc[0]\n",
    "        print(f\"number of documents {topic_info['Count']}\")\n",
    "        if topic_info[\"Count\"] > 0:\n",
    "            print(topic_info[\"Representation\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8fa778-c87b-4f4f-acc5-ef68b9e91759",
   "metadata": {},
   "source": [
    "## BERTopic\n",
    "\n",
    "Seems like the cluster merging results in high imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c487c6-62fe-4805-864f-2ba225796c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bertopic_models[\"big_kw\"].fit(org_file_contents)\n",
    "#bertopic_models[\"big_mmr\"].fit(org_file_contents.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4ca9e-c8f4-44f7-b4b3-8982147a1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_models[\"small_kw\"].fit(preprocess_snakecase(roam_df[\"text\"]).values)\n",
    "bertopic_models[\"small_mmr\"].fit(preprocess_snakecase(roam_df[\"text\"]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc66ac-33c9-45e0-8ffe-edfa617472a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bertopic(bertopic_models[\"small_kw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bec0a-d80e-4f99-8e24-ecc35c3f0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bertopic(bertopic_models[\"small_mmr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1be1b-7999-469d-a6c6-e1ac9a424081",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Bertopic is too aggressive when it comes to merging clusters.\n",
    "\n",
    "LDA is least aggressive, but it seems like NMF pipeline is better (likely because it's easy to optimize the hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102cec5-6f67-41a8-aa40-404557cd9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_models[\"small_mmr\"].topic_sizes_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ea5b0-28e8-43bb-85dc-82286051c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_models[\"small_kw\"].topic_sizes_[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5817cf-6507-4521-90f6-68bba703c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tm.get_topics(roam_df).value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b842673-1207-4296-8f56-6ea0dedb07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.get_topics(roam_df).value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bc55d-d449-4d0f-8007-ece721765a6b",
   "metadata": {},
   "source": [
    "NMF results in highly interpretable topics:\n",
    "\n",
    "- NLP\n",
    "- general software\n",
    "- philosophy and logic\n",
    "- mathematics\n",
    "- information retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efae6d-9e60-4883-a345-7510b9f2b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm.get_top_topic_words()[:,:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noteboard",
   "language": "python",
   "name": "noteboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
