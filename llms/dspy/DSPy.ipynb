{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65152e0-3ca3-4fc1-bae5-3d8c2869c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.cache/pypoetry/virtualenvs/llms-dspy-cWHDaHg3-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "import dspy\n",
    "import dspy.retrieve\n",
    "from llms_dspy.dspy_modules import SimpleRAG\n",
    "from llms_dspy.utils import get_llm, get_qdrant_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239e344-ab18-4615-968f-c392d62376f7",
   "metadata": {},
   "source": [
    "## Configure index\n",
    "\n",
    "The collection name should be the same as in indexing notebook\n",
    "\n",
    "WARNING: you should kill the indexing notebook because otherwis\n",
    "qdrant will not allow you access to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac564c82-a366-422b-a325-6a4078671100",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f63f54-abfc-47ef-b417-abb245d36df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    retriever = get_qdrant_retriever(collection_name=collection_name)\n",
    "except BlockingIOError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63ce97-ece3-4788-bdb8-a8bfa77f1a35",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "If using OpenAI (default option) write your API key to a file and set its path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b75370-4eff-4eeb-bfdb-1638b01a44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key_path='~/.keys/openai_key.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1012aa27-92aa-43ee-ab73-0d28f47f13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_type = \"openai\"\n",
    "\n",
    "llm = get_llm(llm_type, openai_key_path)\n",
    "dspy.settings.configure(lm=llm, rm=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545f6cd6-9686-4f86-a3dc-64b959100ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What libraries have similar functionality to Langchain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bfa3e96-29a5-4d96-a03c-d949847b9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = SimpleRAG(num_passages=10)  # zero-shot, uncompiled version of RAG\n",
    "context, response = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b07c18-b608-419d-a8ad-54cb5b64c577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some libraries that have similar functionality to Langchain are llamaindex, golemacs/refactoring, golemacs/description, golemacs/importinference, and DSPy. These libraries have features such as local file integration, embedding, search, and answering, which are also present in Langchain. However, it is important to note that Langchain is not intended for production use and does not have security features, so\n"
     ]
    }
   ],
   "source": [
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4886bb82-2ffa-4dec-a205-bf6293d70b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produce the answer. We will first look at the context to understand what Langchain is and what it does. Then, we will look at the different use cases and features of Langchain to determine what libraries have similar functionality. Finally, we will provide a list of libraries that have similar functionality to Langchain.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467716ac-537d-49dd-8f88-a3484a55f845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llms/langchain emacs\\n\\norg-roam & langchain\\n\\nDONE local file integration\\n\\nflagship example has notion dump with markdown files\\n\\nlangchain + ChatGPT\\n\\nlangchain + lokalny LLM',\n",
       " 'langchainexpressionlanguage\\n\\ndspy',\n",
       " 'from langchain.vectorstores import Chroma\\n\\nimport indexing\\n\\nembedding = indexing.EmbeddingConfig.get_default().load_embeddings()\\n\\nembedding\\n\\n#db = Chroma(persist_directory=\"vectordb\",embedding_function=embedding, collection_name=\"langchain_rtdocs\")\\n\\nimport chromadb\\n\\nchroma_settings = chromadb.config.Settings(persist_directory=\"./vectordb\")\\n\\nclient = chromadb.Client(chroma_settings)\\n\\nclient.list_collections()',\n",
       " 'llms/langchain\\n\\nRag example from fullstack retrieval\\n\\nTop k search uses this\\n\\nfrom langchain import hub\\n\\nfrom langchain.chat_models import ChatOpenAI\\n\\nfrom langchain.schema import StrOutputParser\\n\\nfrom langchain.schema.runnable import RunnablePassthrough\\n\\nretriever = vectorstore.as_retriever()\\n\\nrag_chain = (\\n\\n{\"context\": retriever, \"question\": RunnablePassthrough()}\\n\\n| prompt\\n\\n| llms\\n\\n| StrOutputParser()',\n",
       " 'llmdocs\\n\\nexact commit\\n\\nDocument loading & preprocessing\\n\\nLangchain has several connectors.\\n\\nPreprocessors can be configured to extract document chunks\\n\\nEmbedding\\n\\nDocuments can be encoded with a huggingface model or using an external API.\\n\\nSearch\\n\\nLibrary connects to vector databases like Qdrant, Chroma et c.\\n\\nAnswering\\n\\nBased on retrieved documents a separate component runs LM to generate answer.',\n",
       " 'langchain prompts',\n",
       " 'nlp/prompts\\n\\nTools\\n\\nllms/langchain\\n\\ndspy\\n\\nllamaindex\\n\\nOLD Prompting tools comparison\\n\\nTools',\n",
       " 'trash\\n\\nTL; DR\\n\\nToolkit for stuff useful for writing gpt-based extensions integrate with components like langchain et c.\\n\\nUse cases\\n\\ngolemacs/refactoring\\n\\ngolemacs/description\\n\\ngolemacs/importinference\\n\\ncode Q&A\\n\\naugmented search with semantic search',\n",
       " 'related to llamaindex\\n\\nTODO org & langchain\\n\\nDONE local file integration\\n\\nflagship example has notion dump with markdown files\\n\\nTODO langchain + embeddings with own model\\n\\nhuggingface embeddings\\n\\n[ ] put huggingface model in flagship example\\n\\nTODO langchain + ChatGPT\\n\\nTODO langchain + lokalny LLM\\n\\ncode & langchain',\n",
       " 'notebooks\\n\\n20231208104827-programmingnotebooks.org::7 (in /home/kuba/Projects/org/roam/20231208104827-programmingnotebooks.org)\\n\\nLangchain is NOT for production use. Here is why ..\\n\\nnice medium article\\n\\nSecurity - why is this even here?\\n\\nLangchain has no such features, so in any case user would need to do this himself\\n\\nDSPy\\n\\nWnioski']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_search_dspy",
   "language": "python",
   "name": "llm_search_dspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
